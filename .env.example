# LLM Provider: "gemini" or "ollama"
LLM_PROVIDER=gemini

# Gemini Configuration (recommended - no local setup needed)
GEMINI_API_KEY=api-key  
GEMINI_MODEL=gemini-2.0-flash

# Ollama Configuration (alternative - requires local setup)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# ChromaDB Configuration
CHROMA_PERSIST_DIR=./data/chroma_db
